{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb45a9b5",
   "metadata": {},
   "source": [
    "# Training and Testing A VGG Model\n",
    "Here we test a VGG from reminder change link!!! [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00b421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms.v2 as v2\n",
    "from our_datasets import Country_images\n",
    "from DenseNet import DenseNet\n",
    "#from Country_dict import comp_country_dict\n",
    "import os\n",
    "\n",
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "#get models\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14315f",
   "metadata": {},
   "source": [
    "## Load our Dataset and Create our dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e496297",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "weights = tv.models.VGG19_BN_Weights.DEFAULT\n",
    "transform = v2.Compose([weights.transforms(), ])\n",
    "\n",
    "\n",
    "dataset_path = os.path.join(\"data\",\"compressed_dataset\")\n",
    "dataset = Country_images(\"country.csv\",dataset_path,transform=transform)\n",
    "num_classes = dataset.get_num_classes()\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset,lengths=[0.7,0.1,0.2])\n",
    "if device == 'cuda':\n",
    "    data_loader_params = {\n",
    "        'batch_size': batch_size,  # Batch size for data loading\n",
    "        'num_workers': 8,  # Number of subprocesses to use for data loading\n",
    "        'persistent_workers': True,  # If True, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the worker dataset instances alive.\n",
    "        'pin_memory': True,  # If True, the data loader will copy Tensors into CUDA pinned memory before returning them. Useful when using GPU.\n",
    "        'pin_memory_device': 'cuda' ,  # Specifies the device where the data should be loaded. Commonly set to use the GPU.\n",
    "    }\n",
    "else:\n",
    "    data_loader_params = {\n",
    "        'batch_size': batch_size,  # Batch size for data loading\n",
    "        #'num_workers': 8,  # Number of subprocesses to use for data loading\n",
    "        #'persistent_workers': True,  # If True, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the worker dataset instances alive.\n",
    "        #'pin_memory': True,  # If True, the data loader will copy Tensors into CUDA pinned memory before returning them. Useful when using GPU.\n",
    "        #'pin_memory_device': 'cuda' ,  # Specifies the device where the data should be loaded. Commonly set to use the GPU.\n",
    "    }\n",
    "train_dataloader      = torch.utils.data.DataLoader(train_dataset, **data_loader_params, shuffle=True)\n",
    "val_dataloader        = torch.utils.data.DataLoader(val_dataset, **data_loader_params, shuffle=True)\n",
    "test_dataloader       = torch.utils.data.DataLoader(test_dataset, **data_loader_params, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79833d2",
   "metadata": {},
   "source": [
    "## Load our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded28ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained_Models\\CNN\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace=True)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace=True)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace=True)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=56, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters:\n",
    "lr = 0.001\n",
    "#maximum learning rate we will let our model train in order to train faster at the start\n",
    "max_lr = 0.01\n",
    "weight_decay = 0.000001\n",
    "EPOCHS = 40\n",
    "#end hyperparameters\n",
    "\n",
    "#model and optimizers\n",
    "model = tv.models.vgg19_bn(num_classes=num_classes)\n",
    "#added data to our model for ease of use (and to prevent passing so many variables to our training function)\n",
    "model.device = device\n",
    "model.name = \"VGG-19BN-1\"\n",
    "model.path = os.path.join(\"Trained_Models\",\"CNN\") #where to save our best model\n",
    "print(model.path)\n",
    "\n",
    "print(model)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "#scales the gradients, neccessary for mixed precision data types to properly converge\n",
    "if device == 'cuda':\n",
    "    scaler = torch.amp.GradScaler()\n",
    "else:\n",
    "    scaler = None\n",
    "#change our learning rate based on far we are in training and if we are improving\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, total_steps=EPOCHS*len(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304dc7e",
   "metadata": {},
   "source": [
    "## Train our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3e86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "EPOCH 1:\n",
      "  batch 100 loss: 4.163289546966553\n",
      "  batch 200 loss: 3.7160258293151855\n",
      "  batch 300 loss: 3.5582242012023926\n",
      "  batch 400 loss: 3.4835238456726074\n",
      "  batch 500 loss: 3.4369733333587646\n",
      "LOSS train 3.4369733333587646 valid 3.552894353866577\n",
      "Accuracy: 0.21587830798082933\n",
      "EPOCH 2:\n",
      "  batch 100 loss: 3.2932915687561035\n",
      "  batch 200 loss: 3.275733709335327\n",
      "  batch 300 loss: 3.2578015327453613\n",
      "  batch 400 loss: 3.252349615097046\n",
      "  batch 500 loss: 3.2402429580688477\n",
      "LOSS train 3.2402429580688477 valid 3.167269229888916\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 3:\n",
      "  batch 100 loss: 3.2288386821746826\n",
      "  batch 200 loss: 3.2197718620300293\n",
      "  batch 300 loss: 3.2163772583007812\n",
      "  batch 400 loss: 3.20436429977417\n",
      "  batch 500 loss: 3.2020270824432373\n",
      "LOSS train 3.2020270824432373 valid 3.164241313934326\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 4:\n",
      "  batch 100 loss: 3.2599616050720215\n",
      "  batch 200 loss: 3.2279086112976074\n",
      "  batch 300 loss: 3.2269511222839355\n",
      "  batch 400 loss: 3.214693784713745\n",
      "  batch 500 loss: 3.2054872512817383\n",
      "LOSS train 3.2054872512817383 valid 3.1646440029144287\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 5:\n",
      "  batch 100 loss: 3.226724624633789\n",
      "  batch 200 loss: 3.21311092376709\n",
      "  batch 300 loss: 3.211962938308716\n",
      "  batch 400 loss: 3.207916736602783\n",
      "  batch 500 loss: 3.2042903900146484\n",
      "LOSS train 3.2042903900146484 valid 3.168712615966797\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 6:\n",
      "  batch 100 loss: 3.2392337322235107\n",
      "  batch 200 loss: 3.2119429111480713\n",
      "  batch 300 loss: 3.2145965099334717\n",
      "  batch 400 loss: 3.211658000946045\n",
      "  batch 500 loss: 3.2085437774658203\n",
      "LOSS train 3.2085437774658203 valid 3.1663873195648193\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 7:\n",
      "  batch 100 loss: 3.2288029193878174\n",
      "  batch 200 loss: 3.2108047008514404\n",
      "  batch 300 loss: 3.210977554321289\n",
      "  batch 400 loss: 3.205474615097046\n",
      "  batch 500 loss: 3.2049736976623535\n",
      "LOSS train 3.2049736976623535 valid 3.1825244426727295\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 8:\n",
      "  batch 100 loss: 3.2249295711517334\n",
      "  batch 200 loss: 3.214308738708496\n",
      "  batch 300 loss: 3.2128303050994873\n",
      "  batch 400 loss: 3.207879066467285\n",
      "  batch 500 loss: 3.207552433013916\n",
      "LOSS train 3.207552433013916 valid 3.1661479473114014\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 9:\n",
      "  batch 100 loss: 3.2464444637298584\n",
      "  batch 200 loss: 3.209279775619507\n",
      "  batch 300 loss: 3.203803539276123\n",
      "  batch 400 loss: 3.2022335529327393\n",
      "  batch 500 loss: 3.2038047313690186\n",
      "LOSS train 3.2038047313690186 valid 3.1689088344573975\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 10:\n",
      "  batch 100 loss: 3.2265923023223877\n",
      "  batch 200 loss: 3.216207981109619\n",
      "  batch 300 loss: 3.2090694904327393\n",
      "  batch 400 loss: 3.2077629566192627\n",
      "  batch 500 loss: 3.2034881114959717\n",
      "LOSS train 3.2034881114959717 valid 3.158780574798584\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 11:\n",
      "  batch 100 loss: 3.1796023845672607\n",
      "  batch 200 loss: 3.1895134449005127\n",
      "  batch 300 loss: 3.191556215286255\n",
      "  batch 400 loss: 3.1974730491638184\n",
      "  batch 500 loss: 3.1967015266418457\n",
      "LOSS train 3.1967015266418457 valid 3.158611297607422\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 12:\n",
      "  batch 100 loss: 3.2129719257354736\n",
      "  batch 200 loss: 3.200670003890991\n",
      "  batch 300 loss: 3.198918342590332\n",
      "  batch 400 loss: 3.1935412883758545\n",
      "  batch 500 loss: 3.194030523300171\n",
      "LOSS train 3.194030523300171 valid 3.1571295261383057\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 13:\n",
      "  batch 100 loss: 3.2117857933044434\n",
      "  batch 200 loss: 3.2081756591796875\n",
      "  batch 300 loss: 3.192413091659546\n",
      "  batch 400 loss: 3.186501979827881\n",
      "  batch 500 loss: 3.1897499561309814\n",
      "LOSS train 3.1897499561309814 valid 3.1571667194366455\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 14:\n",
      "  batch 100 loss: 3.2153408527374268\n",
      "  batch 200 loss: 3.2121472358703613\n",
      "  batch 300 loss: 3.202281951904297\n",
      "  batch 400 loss: 3.1917941570281982\n",
      "  batch 500 loss: 3.18859601020813\n",
      "LOSS train 3.18859601020813 valid 3.1568753719329834\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 15:\n",
      "  batch 100 loss: 3.2052643299102783\n",
      "  batch 200 loss: 3.1855216026306152\n",
      "  batch 300 loss: 3.194171667098999\n",
      "  batch 400 loss: 3.1876213550567627\n",
      "  batch 500 loss: 3.1878607273101807\n",
      "LOSS train 3.1878607273101807 valid 3.157702684402466\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 16:\n",
      "  batch 100 loss: 3.2116892337799072\n",
      "  batch 200 loss: 3.203394889831543\n",
      "  batch 300 loss: 3.205267906188965\n",
      "  batch 400 loss: 3.196885108947754\n",
      "  batch 500 loss: 3.1917014122009277\n",
      "LOSS train 3.1917014122009277 valid 3.1568329334259033\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 17:\n",
      "  batch 100 loss: 3.223470687866211\n",
      "  batch 200 loss: 3.198225975036621\n",
      "  batch 300 loss: 3.1890628337860107\n",
      "  batch 400 loss: 3.1904149055480957\n",
      "  batch 500 loss: 3.1876394748687744\n",
      "LOSS train 3.1876394748687744 valid 3.1556742191314697\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 18:\n",
      "  batch 100 loss: 3.2268006801605225\n",
      "  batch 200 loss: 3.2081408500671387\n",
      "  batch 300 loss: 3.1934492588043213\n",
      "  batch 400 loss: 3.191514253616333\n",
      "  batch 500 loss: 3.1873037815093994\n",
      "LOSS train 3.1873037815093994 valid 3.1569690704345703\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 19:\n",
      "  batch 100 loss: 3.223362684249878\n",
      "  batch 200 loss: 3.2037341594696045\n",
      "  batch 300 loss: 3.1948492527008057\n",
      "  batch 400 loss: 3.190035104751587\n",
      "  batch 500 loss: 3.1867177486419678\n",
      "LOSS train 3.1867177486419678 valid 3.1563260555267334\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 20:\n",
      "  batch 100 loss: 3.224330186843872\n",
      "  batch 200 loss: 3.197890043258667\n",
      "  batch 300 loss: 3.1886026859283447\n",
      "  batch 400 loss: 3.1872589588165283\n",
      "  batch 500 loss: 3.1885530948638916\n",
      "LOSS train 3.1885530948638916 valid 3.1560933589935303\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 21:\n",
      "  batch 100 loss: 3.23354434967041\n",
      "  batch 200 loss: 3.1958446502685547\n",
      "  batch 300 loss: 3.1928517818450928\n",
      "  batch 400 loss: 3.1888160705566406\n",
      "  batch 500 loss: 3.189552068710327\n",
      "LOSS train 3.189552068710327 valid 3.156559944152832\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 22:\n",
      "  batch 100 loss: 3.198843240737915\n",
      "  batch 200 loss: 3.1840693950653076\n",
      "  batch 300 loss: 3.176304340362549\n",
      "  batch 400 loss: 3.182723045349121\n",
      "  batch 500 loss: 3.1877007484436035\n",
      "LOSS train 3.1877007484436035 valid 3.1576733589172363\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 23:\n",
      "  batch 100 loss: 3.2080488204956055\n",
      "  batch 200 loss: 3.2004683017730713\n",
      "  batch 300 loss: 3.1901822090148926\n",
      "  batch 400 loss: 3.184941053390503\n",
      "  batch 500 loss: 3.1896414756774902\n",
      "LOSS train 3.1896414756774902 valid 3.156346082687378\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 24:\n",
      "  batch 100 loss: 3.2375330924987793\n",
      "  batch 200 loss: 3.2072999477386475\n",
      "  batch 300 loss: 3.198810577392578\n",
      "  batch 400 loss: 3.1925809383392334\n",
      "  batch 500 loss: 3.1873795986175537\n",
      "LOSS train 3.1873795986175537 valid 3.156524419784546\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 25:\n",
      "  batch 100 loss: 3.206886053085327\n",
      "  batch 200 loss: 3.2031242847442627\n",
      "  batch 300 loss: 3.198404550552368\n",
      "  batch 400 loss: 3.1838200092315674\n",
      "  batch 500 loss: 3.186284065246582\n",
      "LOSS train 3.186284065246582 valid 3.156085252761841\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 26:\n",
      "  batch 100 loss: 3.2273108959198\n",
      "  batch 200 loss: 3.198430061340332\n",
      "  batch 300 loss: 3.197410821914673\n",
      "  batch 400 loss: 3.1911139488220215\n",
      "  batch 500 loss: 3.1876003742218018\n",
      "LOSS train 3.1876003742218018 valid 3.1556825637817383\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 27:\n",
      "  batch 100 loss: 3.2049851417541504\n",
      "  batch 200 loss: 3.19317889213562\n",
      "  batch 300 loss: 3.195683240890503\n",
      "  batch 400 loss: 3.1906609535217285\n",
      "  batch 500 loss: 3.1871731281280518\n",
      "LOSS train 3.1871731281280518 valid 3.1558785438537598\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 28:\n",
      "  batch 100 loss: 3.212005853652954\n",
      "  batch 200 loss: 3.1968109607696533\n",
      "  batch 300 loss: 3.1927711963653564\n",
      "  batch 400 loss: 3.190261125564575\n",
      "  batch 500 loss: 3.1874496936798096\n",
      "LOSS train 3.1874496936798096 valid 3.1559672355651855\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 29:\n",
      "  batch 100 loss: 3.221243143081665\n",
      "  batch 200 loss: 3.2002511024475098\n",
      "  batch 300 loss: 3.1941678524017334\n",
      "  batch 400 loss: 3.1856887340545654\n",
      "  batch 500 loss: 3.1868529319763184\n",
      "LOSS train 3.1868529319763184 valid 3.1561119556427\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 30:\n",
      "  batch 100 loss: 3.237447738647461\n",
      "  batch 200 loss: 3.2013089656829834\n",
      "  batch 300 loss: 3.1924808025360107\n",
      "  batch 400 loss: 3.187699556350708\n",
      "  batch 500 loss: 3.1864469051361084\n",
      "LOSS train 3.1864469051361084 valid 3.155751943588257\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 31:\n",
      "  batch 100 loss: 3.213505268096924\n",
      "  batch 200 loss: 3.20635986328125\n",
      "  batch 300 loss: 3.197011709213257\n",
      "  batch 400 loss: 3.1903133392333984\n",
      "  batch 500 loss: 3.1888723373413086\n",
      "LOSS train 3.1888723373413086 valid 3.15609073638916\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 32:\n",
      "  batch 100 loss: 3.2032909393310547\n",
      "  batch 200 loss: 3.1892335414886475\n",
      "  batch 300 loss: 3.185168743133545\n",
      "  batch 400 loss: 3.186951160430908\n",
      "  batch 500 loss: 3.1862847805023193\n",
      "LOSS train 3.1862847805023193 valid 3.1561672687530518\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 33:\n",
      "  batch 100 loss: 3.2334933280944824\n",
      "  batch 200 loss: 3.2039358615875244\n",
      "  batch 300 loss: 3.19476056098938\n",
      "  batch 400 loss: 3.1941492557525635\n",
      "  batch 500 loss: 3.1879138946533203\n",
      "LOSS train 3.1879138946533203 valid 3.1560587882995605\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 34:\n",
      "  batch 100 loss: 3.214658260345459\n",
      "  batch 200 loss: 3.204068660736084\n",
      "  batch 300 loss: 3.192826986312866\n",
      "  batch 400 loss: 3.190769672393799\n",
      "  batch 500 loss: 3.1881601810455322\n",
      "LOSS train 3.1881601810455322 valid 3.1556787490844727\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 35:\n",
      "  batch 100 loss: 3.192622661590576\n",
      "  batch 200 loss: 3.1950161457061768\n",
      "  batch 300 loss: 3.175286293029785\n",
      "  batch 400 loss: 3.1773085594177246\n",
      "  batch 500 loss: 3.183943510055542\n",
      "LOSS train 3.183943510055542 valid 3.155654191970825\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 36:\n",
      "  batch 100 loss: 3.2182974815368652\n",
      "  batch 200 loss: 3.195546865463257\n",
      "  batch 300 loss: 3.1948115825653076\n",
      "  batch 400 loss: 3.1915435791015625\n",
      "  batch 500 loss: 3.1843197345733643\n",
      "LOSS train 3.1843197345733643 valid 3.1558241844177246\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 37:\n",
      "  batch 100 loss: 3.2150933742523193\n",
      "  batch 200 loss: 3.198737859725952\n",
      "  batch 300 loss: 3.2037246227264404\n",
      "  batch 400 loss: 3.1948890686035156\n",
      "  batch 500 loss: 3.1875739097595215\n",
      "LOSS train 3.1875739097595215 valid 3.156125783920288\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 38:\n",
      "  batch 100 loss: 3.2107956409454346\n",
      "  batch 200 loss: 3.19317889213562\n",
      "  batch 300 loss: 3.185908794403076\n",
      "  batch 400 loss: 3.1850898265838623\n",
      "  batch 500 loss: 3.187814235687256\n",
      "LOSS train 3.187814235687256 valid 3.156111001968384\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 39:\n",
      "  batch 100 loss: 3.192274332046509\n",
      "  batch 200 loss: 3.198918104171753\n",
      "  batch 300 loss: 3.1910762786865234\n",
      "  batch 400 loss: 3.19463849067688\n",
      "  batch 500 loss: 3.186530590057373\n",
      "LOSS train 3.186530590057373 valid 3.156123638153076\n",
      "Accuracy: 0.25651177328610125\n",
      "EPOCH 40:\n",
      "  batch 100 loss: 3.1970884799957275\n",
      "  batch 200 loss: 3.1854798793792725\n",
      "  batch 300 loss: 3.182967185974121\n",
      "  batch 400 loss: 3.1854398250579834\n",
      "  batch 500 loss: 3.183867931365967\n",
      "LOSS train 3.183867931365967 valid 3.1560306549072266\n",
      "Accuracy: 0.25651177328610125\n"
     ]
    }
   ],
   "source": [
    "#we will call the function we defined in \"Training_Functions.py\"\n",
    "from Training_Functions import TrainModel\n",
    "#Whether we want to train the model, else we test it\n",
    "model_train = True\n",
    "#Whether we want to load a model and fine tune it\n",
    "fine_tune = True\n",
    "#Whether we want to use Automatatic Mixed Precision(Pytorch needs to be new enough)\n",
    "use_amp= True\n",
    "\n",
    "if model_train and fine_tune:\n",
    "    print(\"Starting Fine Tuning\")\n",
    "    checkpoint = torch.load(os.path.join(model.path,\"DenseNet-201-Full-2\"+\"-Best.pth\"),map_location=torch.device(device))\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)\n",
    "    TrainModel(model,EPOCHS, loss_fn, train_dataloader, val_dataloader, optimizer, lr_scheduler, use_amp, scaler)\n",
    "elif model_train:\n",
    "    print(\"Starting Training\")\n",
    "    model = model.to(device)\n",
    "    TrainModel(model,EPOCHS, loss_fn, train_dataloader, val_dataloader, optimizer, lr_scheduler, use_amp, scaler)\n",
    "else:\n",
    "    print(\"Loading Model\")\n",
    "    checkpoint = torch.load(os.path.join( model.path,model.name+\"-Best.pth\"),map_location=torch.device(device))\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46ee3d",
   "metadata": {},
   "source": [
    "## Test our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b243328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2423 / 9598 correct (25.24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25244842675557405"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will call the function we defined in \"Training_Functions.py\"\n",
    "from Training_Functions import TestModel\n",
    "TestModel(model, test_dataloader, loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
