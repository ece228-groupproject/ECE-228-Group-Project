{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb45a9b5",
   "metadata": {},
   "source": [
    "# Training and Testing A Visual Transformer Model\n",
    "Here we test a visual Transfrom ViT from [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00b421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms.v2 as v2\n",
    "from datasets import Country_images\n",
    "from Country_dict import country_dict\n",
    "\n",
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "#get models\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14315f",
   "metadata": {},
   "source": [
    "## Load our Dataset and Create our dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e496297",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "weights = tv.models.ViT_B_16_Weights.DEFAULT\n",
    "transform = v2.Compose([weights.transforms(), ])\n",
    "\n",
    "num_classes = len(country_dict)\n",
    "dataset_path = \"data\\\\compressed_dataset\\\\\"\n",
    "dataset = Country_images(\"data\\\\compressed_dataset\\\\country.csv\",dataset_path,transform=transform)\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset,lengths=[0.7,0.1,0.2])\n",
    "data_loader_params = {\n",
    "    'batch_size': batch_size,  # Batch size for data loading\n",
    "    'num_workers': 10,  # Number of subprocesses to use for data loading\n",
    "    'persistent_workers': True,  # If True, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the worker dataset instances alive.\n",
    "    'pin_memory': True,  # If True, the data loader will copy Tensors into CUDA pinned memory before returning them. Useful when using GPU.\n",
    "    'pin_memory_device': 'cuda' ,  # Specifies the device where the data should be loaded. Commonly set to use the GPU.\n",
    "}\n",
    "train_dataloader      = torch.utils.data.DataLoader(train_dataset, **data_loader_params, shuffle=True)\n",
    "val_dataloader        = torch.utils.data.DataLoader(val_dataset, **data_loader_params, shuffle=True)\n",
    "test_dataloader       = torch.utils.data.DataLoader(test_dataset, **data_loader_params, shuffle=False,in_order=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79833d2",
   "metadata": {},
   "source": [
    "## Load our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc4dc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained_Models\\ViT\\\n",
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.5, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Linear(in_features=768, out_features=124, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters:\n",
    "lr = 0.1\n",
    "#maximum learning rate we will let our model train in order to train faster at the start\n",
    "max_lr = 1.0\n",
    "weight_decay = 0.00001\n",
    "EPOCHS = 100\n",
    "#end hyperparameters\n",
    "\n",
    "#model and optimizers\n",
    "model = tv.models.vit_b_16(weights=weights, dropout=0.5)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=0.8)\n",
    "#scales the gradients, neccessary for mixed precision data types to properly converge\n",
    "scaler = torch.amp.GradScaler(device=device)\n",
    "#change our learning rate based on far we are in training and if we are improving\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, total_steps=EPOCHS*len(train_dataloader))\n",
    "\n",
    "#added data to our model for ease of use (and to prevent passing so many variables to our training function)\n",
    "model.device = device\n",
    "model.name = \"ViT_b_16\"\n",
    "model.path = \"Trained_Models\\\\ViT\\\\\" #where to save our best model\n",
    "print(model.path)\n",
    "#redfine our output layer to output our classes\n",
    "model.heads.head = torch.nn.Linear(in_features=model.heads.head.in_features,out_features=num_classes,bias=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304dc7e",
   "metadata": {},
   "source": [
    "## Train our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e3e86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 100 loss: 0.05004376545548439\n",
      "  batch 200 loss: 0.033041514456272125\n",
      "  batch 300 loss: 0.0266557727009058\n",
      "  batch 400 loss: 0.023180032148957253\n",
      "  batch 500 loss: 0.020939107984304428\n",
      "LOSS train 0.020939107984304428 valid 0.007787656970322132\n",
      "Accuracy: 0.2476\n",
      "EPOCH 2:\n",
      "  batch 100 loss: 0.011309764347970486\n",
      "  batch 200 loss: 0.011052842251956463\n",
      "  batch 300 loss: 0.010859115980565548\n",
      "  batch 400 loss: 0.010692327283322811\n",
      "  batch 500 loss: 0.01054232008755207\n",
      "LOSS train 0.01054232008755207 valid 0.0075785331428050995\n",
      "Accuracy: 0.2476\n",
      "EPOCH 3:\n",
      "  batch 100 loss: 0.009690883569419384\n",
      "  batch 200 loss: 0.00952620804309845\n",
      "  batch 300 loss: 0.009417369961738586\n",
      "  batch 400 loss: 0.009327630512416363\n",
      "  batch 500 loss: 0.00923741515725851\n",
      "LOSS train 0.00923741515725851 valid 0.0074894665740430355\n",
      "Accuracy: 0.2476\n",
      "EPOCH 4:\n",
      "  batch 100 loss: 0.008795890025794506\n",
      "  batch 200 loss: 0.008688902482390404\n",
      "  batch 300 loss: 0.008623488247394562\n",
      "  batch 400 loss: 0.008559324778616428\n",
      "  batch 500 loss: 0.008508754894137383\n",
      "LOSS train 0.008508754894137383 valid 0.007439495995640755\n",
      "Accuracy: 0.2476\n",
      "EPOCH 5:\n",
      "  batch 100 loss: 0.008257349953055382\n",
      "  batch 200 loss: 0.008193609304726124\n",
      "  batch 300 loss: 0.008153771981596947\n",
      "  batch 400 loss: 0.008113168179988861\n",
      "  batch 500 loss: 0.008083442226052284\n",
      "LOSS train 0.008083442226052284 valid 0.007403757888823748\n",
      "Accuracy: 0.2476\n",
      "EPOCH 6:\n",
      "  batch 100 loss: 0.007969344034790993\n",
      "  batch 200 loss: 0.007914913818240166\n",
      "  batch 300 loss: 0.00789635255932808\n",
      "  batch 400 loss: 0.007877454161643982\n",
      "  batch 500 loss: 0.007857303135097027\n",
      "LOSS train 0.007857303135097027 valid 0.007410751190036535\n",
      "Accuracy: 0.2476\n",
      "EPOCH 7:\n",
      "  batch 100 loss: 0.007820759899914265\n",
      "  batch 200 loss: 0.007769934367388487\n",
      "  batch 300 loss: 0.00774346524849534\n",
      "  batch 400 loss: 0.00773204118013382\n",
      "  batch 500 loss: 0.007721446454524994\n",
      "LOSS train 0.007721446454524994 valid 0.007395386230200529\n",
      "Accuracy: 0.2476\n",
      "EPOCH 8:\n",
      "  batch 100 loss: 0.007741397246718407\n",
      "  batch 200 loss: 0.007690433878451586\n",
      "  batch 300 loss: 0.007680672686547041\n",
      "  batch 400 loss: 0.007671935949474573\n",
      "  batch 500 loss: 0.00765778636559844\n",
      "LOSS train 0.00765778636559844 valid 0.007394809741526842\n",
      "Accuracy: 0.2476\n",
      "EPOCH 9:\n",
      "  batch 100 loss: 0.00766465999186039\n",
      "  batch 200 loss: 0.007627119310200214\n",
      "  batch 300 loss: 0.007619908079504967\n",
      "  batch 400 loss: 0.007614942267537117\n",
      "  batch 500 loss: 0.007612201850861311\n",
      "LOSS train 0.007612201850861311 valid 0.0073916553519666195\n",
      "Accuracy: 0.2476\n",
      "EPOCH 10:\n",
      "  batch 100 loss: 0.007668877951800823\n",
      "  batch 200 loss: 0.00763088371604681\n",
      "  batch 300 loss: 0.007610179018229246\n",
      "  batch 400 loss: 0.007599645294249058\n",
      "  batch 500 loss: 0.007591277826577425\n",
      "LOSS train 0.007591277826577425 valid 0.007399611175060272\n",
      "Accuracy: 0.2476\n",
      "EPOCH 11:\n",
      "  batch 100 loss: 0.007608466781675816\n",
      "  batch 200 loss: 0.0075882719829678535\n",
      "  batch 300 loss: 0.00758195947855711\n",
      "  batch 400 loss: 0.007570886984467506\n",
      "  batch 500 loss: 0.007568558678030968\n",
      "LOSS train 0.007568558678030968 valid 0.007400235161185265\n",
      "Accuracy: 0.2476\n",
      "EPOCH 12:\n",
      "  batch 100 loss: 0.007602992467582226\n",
      "  batch 200 loss: 0.00757991848513484\n",
      "  batch 300 loss: 0.007557671982795\n",
      "  batch 400 loss: 0.00755964545533061\n",
      "  batch 500 loss: 0.007554593961685896\n",
      "LOSS train 0.007554593961685896 valid 0.007396003231406212\n",
      "Accuracy: 0.2476\n",
      "EPOCH 13:\n",
      "  batch 100 loss: 0.007602175697684288\n",
      "  batch 200 loss: 0.007579021155834198\n",
      "  batch 300 loss: 0.007556184660643339\n",
      "  batch 400 loss: 0.0075520542450249195\n",
      "  batch 500 loss: 0.007548244670033455\n",
      "LOSS train 0.007548244670033455 valid 0.007406428921967745\n",
      "Accuracy: 0.2476\n",
      "EPOCH 14:\n",
      "  batch 100 loss: 0.00763649120926857\n",
      "  batch 200 loss: 0.007570041809231043\n",
      "  batch 300 loss: 0.007556309923529625\n",
      "  batch 400 loss: 0.007546883076429367\n",
      "  batch 500 loss: 0.007539177313446999\n",
      "LOSS train 0.007539177313446999 valid 0.007390739396214485\n",
      "Accuracy: 0.2476\n",
      "EPOCH 15:\n",
      "  batch 100 loss: 0.007587251253426075\n",
      "  batch 200 loss: 0.007556089665740728\n",
      "  batch 300 loss: 0.007545470260083675\n",
      "  batch 400 loss: 0.007537357043474913\n",
      "  batch 500 loss: 0.007532415445894003\n",
      "LOSS train 0.007532415445894003 valid 0.007402896415442228\n",
      "Accuracy: 0.2476\n",
      "EPOCH 16:\n",
      "  batch 100 loss: 0.007593807764351368\n",
      "  batch 200 loss: 0.007544719148427248\n",
      "  batch 300 loss: 0.007540432270616293\n",
      "  batch 400 loss: 0.007532601710408926\n",
      "  batch 500 loss: 0.0075216395780444145\n",
      "LOSS train 0.0075216395780444145 valid 0.007414669264107943\n",
      "Accuracy: 0.2476\n",
      "EPOCH 17:\n",
      "  batch 100 loss: 0.007615855894982815\n",
      "  batch 200 loss: 0.007549067959189415\n",
      "  batch 300 loss: 0.007532523013651371\n",
      "  batch 400 loss: 0.007523289881646633\n",
      "  batch 500 loss: 0.007516517303884029\n",
      "LOSS train 0.007516517303884029 valid 0.00740839634090662\n",
      "Accuracy: 0.2476\n",
      "EPOCH 18:\n",
      "  batch 100 loss: 0.007580629084259272\n",
      "  batch 200 loss: 0.007535238284617662\n",
      "  batch 300 loss: 0.007522153202444315\n",
      "  batch 400 loss: 0.007511001545935869\n",
      "  batch 500 loss: 0.0075141326524317265\n",
      "LOSS train 0.0075141326524317265 valid 0.007409841287881136\n",
      "Accuracy: 0.2476\n",
      "EPOCH 19:\n",
      "  batch 100 loss: 0.007583191152662039\n",
      "  batch 200 loss: 0.007545462343841791\n",
      "  batch 300 loss: 0.007531259208917618\n",
      "  batch 400 loss: 0.007518690545111895\n",
      "  batch 500 loss: 0.007509724702686071\n",
      "LOSS train 0.007509724702686071 valid 0.007418567780405283\n",
      "Accuracy: 0.2476\n",
      "EPOCH 20:\n",
      "  batch 100 loss: 0.007548151072114706\n",
      "  batch 200 loss: 0.007535995449870825\n",
      "  batch 300 loss: 0.0075252121314406395\n",
      "  batch 400 loss: 0.007514637429267168\n",
      "  batch 500 loss: 0.007504782639443874\n",
      "LOSS train 0.007504782639443874 valid 0.007416019216179848\n",
      "Accuracy: 0.2476\n",
      "EPOCH 21:\n",
      "  batch 100 loss: 0.007539334706962109\n",
      "  batch 200 loss: 0.007511102128773928\n",
      "  batch 300 loss: 0.0075095840729773045\n",
      "  batch 400 loss: 0.007506655063480139\n",
      "  batch 500 loss: 0.007500177714973688\n",
      "LOSS train 0.007500177714973688 valid 0.007415249478071928\n",
      "Accuracy: 0.2476\n",
      "EPOCH 22:\n",
      "  batch 100 loss: 0.0075254845432937145\n",
      "  batch 200 loss: 0.007498478516936302\n",
      "  batch 300 loss: 0.007501475978642702\n",
      "  batch 400 loss: 0.007495581172406673\n",
      "  batch 500 loss: 0.0074930693954229355\n",
      "LOSS train 0.0074930693954229355 valid 0.007431673817336559\n",
      "Accuracy: 0.2476\n",
      "EPOCH 23:\n",
      "  batch 100 loss: 0.007565563544631004\n",
      "  batch 200 loss: 0.007510957773774862\n",
      "  batch 300 loss: 0.007503512781113386\n",
      "  batch 400 loss: 0.007491691503673792\n",
      "  batch 500 loss: 0.0074873254634439945\n",
      "LOSS train 0.0074873254634439945 valid 0.00743994303047657\n",
      "Accuracy: 0.2476\n",
      "EPOCH 24:\n",
      "  batch 100 loss: 0.007545290514826775\n",
      "  batch 200 loss: 0.0075086853466928005\n",
      "  batch 300 loss: 0.0074925972148776054\n",
      "  batch 400 loss: 0.007488379720598459\n",
      "  batch 500 loss: 0.007484088651835918\n",
      "LOSS train 0.007484088651835918 valid 0.007454469334334135\n",
      "Accuracy: 0.2476\n",
      "EPOCH 25:\n",
      "  batch 100 loss: 0.007545230910181999\n",
      "  batch 200 loss: 0.007517463061958551\n",
      "  batch 300 loss: 0.0075020454823970795\n",
      "  batch 400 loss: 0.007487206254154444\n",
      "  batch 500 loss: 0.007481507491320372\n",
      "LOSS train 0.007481507491320372 valid 0.007458437234163284\n",
      "Accuracy: 0.2476\n",
      "EPOCH 26:\n",
      "  batch 100 loss: 0.007560513447970152\n",
      "  batch 200 loss: 0.007506952621042728\n",
      "  batch 300 loss: 0.007484888657927513\n",
      "  batch 400 loss: 0.007480330765247345\n",
      "  batch 500 loss: 0.007479660212993622\n",
      "LOSS train 0.007479660212993622 valid 0.007465574890375137\n",
      "Accuracy: 0.2476\n",
      "EPOCH 27:\n",
      "  batch 100 loss: 0.007526959292590618\n",
      "  batch 200 loss: 0.007493328768759966\n",
      "  batch 300 loss: 0.007487520109862089\n",
      "  batch 400 loss: 0.007477844133973122\n",
      "  batch 500 loss: 0.00747391814365983\n",
      "LOSS train 0.00747391814365983 valid 0.007486056070774794\n",
      "Accuracy: 0.2476\n",
      "EPOCH 28:\n",
      "  batch 100 loss: 0.007520017214119434\n",
      "  batch 200 loss: 0.007492502685636282\n",
      "  batch 300 loss: 0.007477884646505117\n",
      "  batch 400 loss: 0.0074796369299292564\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_train:\n\u001b[32m      6\u001b[39m     model = model.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[43mTrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_train:\n\u001b[32m      9\u001b[39m     checkpoint = torch.load(model.path+model.name+\u001b[33m\"\u001b[39m\u001b[33m-best\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\Documents\\GitHub\\ECE-228-Group-Project\\Training_Functions.py:30\u001b[39m, in \u001b[36mTrainModel\u001b[39m\u001b[34m(model, EPOCHS, loss_fn, train_loader, val_loader, optimizer, lr_scheduler, scaler)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[32m     29\u001b[39m model.train(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m avg_loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m running_vloss = \u001b[32m0.0\u001b[39m\n\u001b[32m     33\u001b[39m num_correct = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\Documents\\GitHub\\ECE-228-Group-Project\\Training_Functions.py:111\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, training_loader, epoch_index, loss_fn, tb_writer, optimizer, lr_scheduler, scaler)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scaler:\u001b[38;5;66;03m#if were scaling our loss\u001b[39;00m\n\u001b[32m    110\u001b[39m     scaler.scale(loss).backward()\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     old_scaler = scaler.get_scale()\n\u001b[32m    113\u001b[39m     scaler.update()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:461\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    458\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    459\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:355\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:355\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#we will call the function we defined in \"Training_Functions.py\"\n",
    "from Training_Functions import TrainModel\n",
    "model_train = True\n",
    "\n",
    "if model_train:\n",
    "    model = model.to(device)\n",
    "    TrainModel(model,EPOCHS, loss_fn, train_dataloader, val_dataloader, optimizer, lr_scheduler, scaler)\n",
    "if not model_train:\n",
    "    checkpoint = torch.load(model.path+model.name+\"-best\")\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46ee3d",
   "metadata": {},
   "source": [
    "## Test our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b243328",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 9.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 211, in collate\n    return [\n           ^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in <listcomp>\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 270, in collate_tensor_fn\n    storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\storage.py\", line 1198, in _new_shared\n    untyped_storage = torch.UntypedStorage._new_shared(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\storage.py\", line 410, in _new_shared\n    return cls._new_using_filename_cpu(size)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Couldn't open shared file mapping: <torch_11696_3519581106_2>, error code: <1455>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#we will call the function we defined in \"Training_Functions.py\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mTraining_Functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TestModel\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mTestModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\Documents\\GitHub\\ECE-228-Group-Project\\Training_Functions.py:143\u001b[39m, in \u001b[36mTestModel\u001b[39m\u001b[34m(model, test_loader, loss_fn)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Disable gradient computation and reduce memory consumption.\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1488\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1486\u001b[39m     worker_id, data = \u001b[38;5;28mself\u001b[39m._task_info.pop(\u001b[38;5;28mself\u001b[39m._rcvd_idx)\n\u001b[32m   1487\u001b[39m     \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m   1491\u001b[39m idx, data = \u001b[38;5;28mself\u001b[39m._get_data()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1550\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data, worker_idx)\u001b[39m\n\u001b[32m   1548\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:750\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    747\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[32m    748\u001b[39m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mRuntimeError\u001b[39m: Caught RuntimeError in DataLoader worker process 9.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 211, in collate\n    return [\n           ^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in <listcomp>\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 270, in collate_tensor_fn\n    storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\storage.py\", line 1198, in _new_shared\n    untyped_storage = torch.UntypedStorage._new_shared(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\storage.py\", line 410, in _new_shared\n    return cls._new_using_filename_cpu(size)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Couldn't open shared file mapping: <torch_11696_3519581106_2>, error code: <1455>\n"
     ]
    }
   ],
   "source": [
    "#we will call the function we defined in \"Training_Functions.py\"\n",
    "from Training_Functions import TestModel\n",
    "TestModel(model, test_dataloader, loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
